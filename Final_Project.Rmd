---
title: "Prediction Assignment"
author: "Sebastian Castillo"
date: "2019-01-03"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, error = FALSE)
```


```{r, echo=FALSE, message=FALSE}
library(lattice)
library(ggplot2)
library(caret)
library(rpart)
library(rpart.plot)
library(corrplot)
library(rattle)
library(randomForest)
library(RColorBrewer)
library(randomForest)
library(gbm)

```


# INTRODUCTION 

This is the final report of the Peer Assessment project from the Practical Machine Learning course, which is a part of the Data Science Specialization. The goal of the project was to fit a Machine Learning model in order to predict the way some weight exercises were performed given data about the movement of subjects.The machine learning algorithm, which uses the classe variable in the training set, is applied to the 20 test cases available in the test data. 

The training data for this project are available here: [link](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv)

The test data are available here: [link](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv)

# Understanding the Data

Devices such as Jawbone Up, Nike FuelBand, and Fitbit can enable collecting a large amount of data about someone’s physical activity. These devices are used by the enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. However, even though these enthusiasts regularly quantify how much of a particular activity they do, they rarely quantify how well they do it. In this project, the goal is to use data from accelerometers on the belt, forearm, arm, and dumbell of six participants. They were asked to perform barbell lifts correctly and incorrectly in five different ways.

# Load the dataset 

```{r, echo=FALSE}

url_train <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
url_quiz  <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
data_train <- read.csv(url(url_train), strip.white = TRUE, na.strings = c("NA",""))
data_quiz  <- read.csv(url(url_quiz),  strip.white = TRUE, na.strings = c("NA",""))

```

Create two partitions (75 % and 25 %) within the original training dataset.

```{r}
in_train  <- createDataPartition(data_train$classe, p=0.75, list=FALSE)
train_set <- data_train[ in_train, ]
test_set  <- data_train[-in_train, ]
dim(train_set)
dim(test_set)

```

The two datasets have a large number of NA values as well as near-zero-variance variables, so they will be removed.

```{r}
nzv_var <- nearZeroVar(train_set)
train_set <- train_set[ , -nzv_var]
test_set  <- test_set [ , -nzv_var]
dim(train_set)
dim(test_set)

```


Remove variables that are mostly NA. A threshlod of 95 % is selected.

```{r}
na_var <- sapply(train_set, function(x) mean(is.na(x))) > 0.95
train_set <- train_set[ , na_var == FALSE]
test_set  <- test_set [ , na_var == FALSE]
```

Columns 1 to 5 are identification variables only, they will be removed.

```{r}
train_set <- train_set[ , -(1:5)]
test_set  <- test_set [ , -(1:5)]
dim(train_set)
dim(test_set)
```

The number of variables for the analysis has been reduced from 160 to 54.

# Correlation Analysis

Perform a correlation analysis between the variables before the modeling work itself is done. Select “FPC” for the first principal component order.

```{r}
corr_matrix <- cor(train_set[ , -54])
corrplot(corr_matrix, order = "FPC", method = "circle", type = "lower",
         tl.cex = 0.6, tl.col = rgb(0, 0, 0))
```

# Fitting prediction models

In this part three different models will be fitted to the trainingdata (and evaluated against the testdata).

# Random Forest (RF)

```{r}
# Random Forest
set.seed(131055)
trControl <- trainControl(method = "cv", number = 5, verboseIter = FALSE)
mod_rf <- train(classe ~ ., data = train_set, method = "rf", trControl = trControl)
# mod_rf$finalModel; suppress: to much output
predict_rf <- predict(mod_rf, newdata = test_set)
confMat_rf <- confusionMatrix(predict_rf, test_set$classe)
confMat_rf
```

## Plot RF

```{r}
plot(confMat_rf$table, main = paste("Random Forest Accuracy =", round(confMat_rf$overall["Accuracy"], 4)))
```


## Linear Discriminant Analysis (LDA)

```{r}
set.seed(131055)
trControl <- trainControl(method = "cv", number = 5, verboseIter = FALSE)
mod_lda <- train(classe ~ ., data = train_set, method = "lda", trControl = trControl)
# mod_lda$finalModel; suppress: to much output
predict_lda <- predict(mod_lda, newdata = test_set)
confMat_lda <- confusionMatrix(predict_lda, test_set$classe)
confMat_lda
```

## Plot LDA

```{r}
plot(confMat_lda$table, main = paste("Linear Discriminant Accuracy =", round(confMat_lda$overall["Accuracy"], 4)))
```

## K Nearest Neighbor (KNN)

```{r}
set.seed(131055)
trControl <- trainControl(method = "cv", number = 5, verboseIter = FALSE)
mod_knn <- train(classe ~ ., data = train_set, method = "knn", trControl = trControl)
# mod_knn$finalModel; suppress: to much output
predict_knn <- predict(mod_knn, newdata = test_set)
confMat_knn <- confusionMatrix(predict_knn, test_set$classe)
confMat_knn
```

Plot KNN

```{r}
plot(confMat_knn$table, main = paste("K Nearest Neighbor Accuracy =", round(confMat_knn$overall["Accuracy"], 4)))
```

## Final Prediction on the test set

All models were trained with crossvalidation.   

Sorted on performance to predict the test data, the ranking of the different models is as follows: 

*1: `r round(confMat_rf$overall["Accuracy"], 4)` (Random Forest)  
*2: `r round(confMat_knn$overall["Accuracy"], 4)` (KNN)  
*3: `r round(confMat_lda$overall["Accuracy"], 4)` (LDA) 

On accuracy, Random Forest is a clear winner. And it is clear from the corresponding plot that all categories of classe are more or less equally predicted.   

So for the final prediction on the extra test-set the final Random Forest model is choosen.

```{r}
predict_final <- predict(mod_rf, newdata = test_set)
predict_final
```